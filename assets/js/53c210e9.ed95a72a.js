"use strict";(self.webpackChunkpathlit_docs=self.webpackChunkpathlit_docs||[]).push([[6649],{5680:(e,n,l)=>{l.r(n),l.d(n,{assets:()=>z,contentTitle:()=>G,default:()=>S,frontMatter:()=>P,metadata:()=>y,toc:()=>T});var i=l(4848),s=l(8453),a=l(6540),t=l(4164),r=l(3104),o=l(6347),c=l(205),d=l(7485),u=l(1682),h=l(9466);function m(e){return a.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function g(e){const{values:n,children:l}=e;return(0,a.useMemo)((()=>{const e=n??function(e){return m(e).map((e=>{let{props:{value:n,label:l,attributes:i,default:s}}=e;return{value:n,label:l,attributes:i,default:s}}))}(l);return function(e){const n=(0,u.X)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,l])}function x(e){let{value:n,tabValues:l}=e;return l.some((e=>e.value===n))}function p(e){let{queryString:n=!1,groupId:l}=e;const i=(0,o.W6)(),s=function(e){let{queryString:n=!1,groupId:l}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!l)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return l??null}({queryString:n,groupId:l});return[(0,d.aZ)(s),(0,a.useCallback)((e=>{if(!s)return;const n=new URLSearchParams(i.location.search);n.set(s,e),i.replace({...i.location,search:n.toString()})}),[s,i])]}function j(e){const{defaultValue:n,queryString:l=!1,groupId:i}=e,s=g(e),[t,r]=(0,a.useState)((()=>function(e){let{defaultValue:n,tabValues:l}=e;if(0===l.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!x({value:n,tabValues:l}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${l.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const i=l.find((e=>e.default))??l[0];if(!i)throw new Error("Unexpected error: 0 tabValues");return i.value}({defaultValue:n,tabValues:s}))),[o,d]=p({queryString:l,groupId:i}),[u,m]=function(e){let{groupId:n}=e;const l=function(e){return e?`docusaurus.tab.${e}`:null}(n),[i,s]=(0,h.Dv)(l);return[i,(0,a.useCallback)((e=>{l&&s.set(e)}),[l,s])]}({groupId:i}),j=(()=>{const e=o??u;return x({value:e,tabValues:s})?e:null})();(0,c.A)((()=>{j&&r(j)}),[j]);return{selectedValue:t,selectValue:(0,a.useCallback)((e=>{if(!x({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);r(e),d(e),m(e)}),[d,m,s]),tabValues:s}}var v=l(2303);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function f(e){let{className:n,block:l,selectedValue:s,selectValue:a,tabValues:o}=e;const c=[],{blockElementScrollPositionUntilNextRender:d}=(0,r.a_)(),u=e=>{const n=e.currentTarget,l=c.indexOf(n),i=o[l].value;i!==s&&(d(n),a(i))},h=e=>{let n=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const l=c.indexOf(e.currentTarget)+1;n=c[l]??c[0];break}case"ArrowLeft":{const l=c.indexOf(e.currentTarget)-1;n=c[l]??c[c.length-1];break}}n?.focus()};return(0,i.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,t.A)("tabs",{"tabs--block":l},n),children:o.map((e=>{let{value:n,label:l,attributes:a}=e;return(0,i.jsx)("li",{role:"tab",tabIndex:s===n?0:-1,"aria-selected":s===n,ref:e=>c.push(e),onKeyDown:h,onClick:u,...a,className:(0,t.A)("tabs__item",b.tabItem,a?.className,{"tabs__item--active":s===n}),children:l??n},n)}))})}function M(e){let{lazy:n,children:l,selectedValue:s}=e;const t=(Array.isArray(l)?l:[l]).filter(Boolean);if(n){const e=t.find((e=>e.props.value===s));return e?(0,a.cloneElement)(e,{className:"margin-top--md"}):null}return(0,i.jsx)("div",{className:"margin-top--md",children:t.map(((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==s})))})}function L(e){const n=j(e);return(0,i.jsxs)("div",{className:(0,t.A)("tabs-container",b.tabList),children:[(0,i.jsx)(f,{...e,...n}),(0,i.jsx)(M,{...e,...n})]})}function A(e){const n=(0,v.A)();return(0,i.jsx)(L,{...e,children:m(e.children)},String(n))}const w={tabItem:"tabItem_Ymn6"};function I(e){let{children:n,hidden:l,className:s}=e;return(0,i.jsx)("div",{role:"tabpanel",className:(0,t.A)(w.tabItem,s),hidden:l,children:n})}const P={},G="Large Language Models (LLMs)",y={id:"Chat UI/Models",title:"Large Language Models (LLMs)",description:"This document presents an organized overview of various Large Language Models (LLMs) from different creators, such as Meta, Google, and OpenAI. Here you'll find information on their specifications and intended use cases.",source:"@site/docs/Chat UI/Models.md",sourceDirName:"Chat UI",slug:"/Chat UI/Models",permalink:"/Pathlit-Docs/docs/Chat UI/Models",draft:!1,unlisted:!1,editUrl:"https://github.com/Pathlit-Inc/Pathlit-Docs/docs/Chat UI/Models.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Advanced Settings for Chat UI",permalink:"/Pathlit-Docs/docs/Chat UI/Settings/Advanced Settings"},next:{title:"Workflows",permalink:"/Pathlit-Docs/docs/category/workflows"}},z={},T=[{value:"OpenAI&#39;s LLMs",id:"openais-llms",level:2},{value:"GPT-3.5-turbo-1106",id:"gpt-35-turbo-1106",level:3},{value:"GPT-4-1106-preview",id:"gpt-4-1106-preview",level:3},{value:"Meta&#39;s LLMs",id:"metas-llms",level:2},{value:"Meta Llama2-13b-chat",id:"meta-llama2-13b-chat",level:3},{value:"Meta Llama2-70b-chat",id:"meta-llama2-70b-chat",level:3},{value:"Google&#39;s LLMs",id:"googles-llms",level:2},{value:"Gemini 1.0 Pro",id:"gemini-10-pro",level:3},{value:"Google Gemma-7b",id:"google-gemma-7b",level:3},{value:"Google Gemma-7b-it",id:"google-gemma-7b-it",level:3},{value:"Google Gemma-2b",id:"google-gemma-2b",level:3},{value:"Google Gemma-2b-it",id:"google-gemma-2b-it",level:3},{value:"Amazon&#39;s LLMs",id:"amazons-llms",level:2},{value:"Amazon Titan-text-lite-v",id:"amazon-titan-text-lite-v",level:3},{value:"Amazon Titan-text-expr",id:"amazon-titan-text-expr",level:3},{value:"Microsofts&#39;s LLMs",id:"microsoftss-llms",level:2},{value:"Microsoft/Phi-2",id:"microsoftphi-2",level:3},{value:"Mistral&#39;s LLMs",id:"mistrals-llms",level:2},{value:"Mistral-8x7b-32768",id:"mistral-8x7b-32768",level:3},{value:"MistralAI/Mistral-7B-v0",id:"mistralaimistral-7b-v0",level:3}];function C(e){const n={h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"large-language-models-llms",children:"Large Language Models (LLMs)"}),"\n",(0,i.jsx)(n.p,{children:"This document presents an organized overview of various Large Language Models (LLMs) from different creators, such as Meta, Google, and OpenAI. Here you'll find information on their specifications and intended use cases."}),"\n",(0,i.jsxs)(A,{defaultValue:"meta",values:[{label:"OpenAI",value:"openai"},{label:"Meta",value:"meta"},{label:"Google",value:"google"},{label:"Amazon",value:"amazon"},{label:"Microsoft",value:"microsoft"},{label:"Mistral",value:"mistral"}],children:[(0,i.jsxs)(I,{value:"openai",children:[(0,i.jsx)(n.h2,{id:"openais-llms",children:"OpenAI's LLMs"}),(0,i.jsxs)(A,{defaultValue:"gpt-3-5-turbo",values:[{label:"GPT-3.5-turbo-1106",value:"gpt-3-5-turbo"},{label:"GPT-4-1106-preview",value:"gpt-4-preview"}],children:[(0,i.jsxs)(I,{value:"gpt-3-5-turbo",children:[(0,i.jsx)(n.h3,{id:"gpt-35-turbo-1106",children:"GPT-3.5-turbo-1106"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," OpenAI"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," Assumed to align with GPT-3.5's parameters, potentially in the hundreds of billions."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," High-speed, responsive interaction for a variety of use cases."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," An iteration of the GPT-3.5 model with optimizations for turbocharged performance, maintaining the model's robustness while enhancing speed."]}),"\n"]})]}),(0,i.jsxs)(I,{value:"gpt-4-preview",children:[(0,i.jsx)(n.h3,{id:"gpt-4-1106-preview",children:"GPT-4-1106-preview"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," OpenAI"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," Likely to exceed those of GPT-3.5, reflecting the next step in GPT architecture."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Advanced AI applications previewing the capabilities of the next generational leap in language models."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," A sneak peek at the potential of GPT-4, offering insights into the advancements in natural language processing and generation."]}),"\n"]})]})]})]}),(0,i.jsxs)(I,{value:"meta",children:[(0,i.jsx)(n.h2,{id:"metas-llms",children:"Meta's LLMs"}),(0,i.jsxs)(A,{defaultValue:"llama2-13b",values:[{label:"Llama2-13b-chat",value:"llama2-13b"},{label:"Llama2-70b-chat",value:"llama2-70b"}],children:[(0,i.jsxs)(I,{value:"llama2-13b",children:[(0,i.jsx)(n.h3,{id:"meta-llama2-13b-chat",children:"Meta Llama2-13b-chat"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," Meta Platforms, Inc."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," 13 billion."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Chat and conversational AI."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," Optimized for engaging and detailed conversations, ideal for chat applications."]}),"\n"]})]}),(0,i.jsxs)(I,{value:"llama2-70b",children:[(0,i.jsx)(n.h3,{id:"meta-llama2-70b-chat",children:"Meta Llama2-70b-chat"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," Meta Platforms, Inc."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," 70 billion."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Advanced deep learning with extensive contextual understanding."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," Suitable for nuanced conversation generation across a wide array of topics."]}),"\n"]})]})]})]}),(0,i.jsxs)(I,{value:"google",children:[(0,i.jsx)(n.h2,{id:"googles-llms",children:"Google's LLMs"}),(0,i.jsxs)(A,{defaultValue:"gemini",values:[{label:"Gemini 1.0 Pro",value:"gemini"},{label:"Gemma-7b",value:"gemma-7b"},{label:"Gemma-7b-it",value:"gemma-7b-it"},{label:"Gemma-2b",value:"gemma-2b"},{label:"Gemma-2b-it",value:"gemma-2b-it"}],children:[(0,i.jsxs)(I,{value:"gemini",children:[(0,i.jsx)(n.h3,{id:"gemini-10-pro",children:"Gemini 1.0 Pro"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," Presumed independent entity"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," Estimated at 1 billion"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Professional-level conversational capabilities"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," Engineered for depth in conversation, this model can engage in complex dialogues across various professional domains."]}),"\n"]})]}),(0,i.jsxs)(I,{value:"gemma-7b",children:[(0,i.jsx)(n.h3,{id:"google-gemma-7b",children:"Google Gemma-7b"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," Google."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," 7 billion."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Versatile applications in multiple languages."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," A general-purpose model designed for diverse language tasks and adaptability."]}),"\n"]})]}),(0,i.jsxs)(I,{value:"gemma-7b-it",children:[(0,i.jsx)(n.h3,{id:"google-gemma-7b-it",children:"Google Gemma-7b-it"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," Google."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," 7 billion"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Tailored for tasks requiring proficiency..."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," Provides nuanced understanding and generation..."]}),"\n"]})]}),(0,i.jsxs)(I,{value:"gemma-2b",children:[(0,i.jsx)(n.h3,{id:"google-gemma-2b",children:"Google Gemma-2b"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," Google."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," 2 billion."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Efficient language processing for tasks with fewer computational demands."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," A compact model that balances advanced research and efficiency in language tasks."]}),"\n"]})]}),(0,i.jsxs)(I,{value:"gemma-2b-it",children:[(0,i.jsx)(n.h3,{id:"google-gemma-2b-it",children:"Google Gemma-2b-it"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," Google."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," 2 billion"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Streamlined processing..."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," Geared towards applications needing quick, efficient..."]}),"\n"]})]})]})]}),(0,i.jsxs)(I,{value:"amazon",children:[(0,i.jsx)(n.h2,{id:"amazons-llms",children:"Amazon's LLMs"}),(0,i.jsxs)(A,{defaultValue:"titan-text-lite",values:[{label:"Amazon Titan-text-lite-v",value:"titan-text-lite"},{label:"Amazon Titan-text-expr",value:"titan-text-expr"}],children:[(0,i.jsxs)(I,{value:"titan-text-lite",children:[(0,i.jsx)(n.h3,{id:"amazon-titan-text-lite-v",children:"Amazon Titan-text-lite-v"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," Amazon Web Services"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," Undisclosed, with a focus on fast processing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Quick text response generation for scalable applications"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," A nimble version of Amazon's Titan model, designed for rapid interaction without sacrificing too much depth."]}),"\n"]})]}),(0,i.jsxs)(I,{value:"titan-text-expr",children:[(0,i.jsx)(n.h3,{id:"amazon-titan-text-expr",children:"Amazon Titan-text-expr"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," Amazon Web Services"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," Presumably higher than the lite version for more expressive interactions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Rich, nuanced text generation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," Focused on generating expressive and detailed responses, this model caters to applications where depth of language is paramount."]}),"\n"]})]})]})]}),(0,i.jsxs)(I,{value:"microsoft",children:[(0,i.jsx)(n.h2,{id:"microsoftss-llms",children:"Microsofts's LLMs"}),(0,i.jsx)(A,{defaultValue:"microsoft-phi-2",values:[{label:"Microsoft/Phi-2",value:"microsoft-phi-2"}],children:(0,i.jsxs)(I,{value:"microsoft-phi-2",children:[(0,i.jsx)(n.h3,{id:"microsoftphi-2",children:"Microsoft/Phi-2"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," Microsoft"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," Not publicly disclosed"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Multi-purpose AI with a focus on versatility and integration"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," A testament to Microsoft's AI endeavors, aimed at offering both breadth and depth in language understanding and generation."]}),"\n"]})]})})]}),(0,i.jsxs)(I,{value:"mistral",children:[(0,i.jsx)(n.h2,{id:"mistrals-llms",children:"Mistral's LLMs"}),(0,i.jsxs)(A,{defaultValue:"mistral-8x7b",values:[{label:"Mistral-8x7b-32768",value:"mistral-8x7b"},{label:"MistralAI/Mistral-7B-v0",value:"mistralai-7b"}],children:[(0,i.jsxs)(I,{value:"mistral-8x7b",children:[(0,i.jsx)(n.h3,{id:"mistral-8x7b-32768",children:"Mistral-8x7b-32768"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," Mistral AI or an associated entity."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," Implied to be 56 billion (8x7b)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Handling extensive datasets and complex NLP tasks."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," A model geared towards in-depth data analysis and sophisticated language comprehension."]}),"\n"]})]}),(0,i.jsxs)(I,{value:"mistralai-7b",children:[(0,i.jsx)(n.h3,{id:"mistralaimistral-7b-v0",children:"MistralAI/Mistral-7B-v0"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Creator:"})," Mistral AI."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"})," 7 billion."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Specialization:"})," Broad-purpose language understanding and generation."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," An early version of Mistral AI's 7B model, catering to a range of conversational and text-based tasks."]}),"\n"]})]})]})]})]})]})}function S(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(C,{...e})}):C(e)}},8453:(e,n,l)=>{l.d(n,{R:()=>t,x:()=>r});var i=l(6540);const s={},a=i.createContext(s);function t(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);